{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "133005bf",
      "metadata": {
        "id": "133005bf",
        "outputId": "7c5c3f9c-bed3-4e28-d862-704887f6ce4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Natasha Kayla\\anaconda3\\envs\\text_mining\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import fasttext\n",
        "from huggingface_hub import hf_hub_download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6599331",
      "metadata": {
        "id": "c6599331"
      },
      "outputs": [],
      "source": [
        "# hf_hub_download(repo_id=\"facebook/fasttext-id-vectors\",\n",
        "#                 filename=\"model.bin\",\n",
        "#                 cache_dir=\"./models\",\n",
        "#                 force_download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09e6f779",
      "metadata": {
        "id": "09e6f779"
      },
      "outputs": [],
      "source": [
        "model_path = \"models/models--facebook--fasttext-id-vectors/snapshots/77c30f24dea48d507180be003faad9ebdc070621/model.bin\"\n",
        "model_fasttext = fasttext.load_model(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17671a09",
      "metadata": {
        "id": "17671a09",
        "outputId": "04931a9d-ddf3-4dd0-da07-5865defa420c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0.7911218404769897, 'canti'),\n",
              " (0.7720605134963989, 'cantikdan'),\n",
              " (0.7554269433021545, 'cantik.Cantik'),\n",
              " (0.7534511089324951, 'cantikan'),\n",
              " (0.751379668712616, 'cantiknya'),\n",
              " (0.7337489724159241, '.cantik'),\n",
              " (0.7271543741226196, 'cantik.Ia'),\n",
              " (0.7211070656776428, 'cantk'),\n",
              " (0.7113025188446045, 'cantik.Di'),\n",
              " (0.7021833062171936, 'menawan')]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_fasttext.get_nearest_neighbors(\"cantik\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7bea01b",
      "metadata": {
        "id": "e7bea01b"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d69b030e",
      "metadata": {
        "id": "d69b030e"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b4446575",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4446575",
        "outputId": "9e5d3c9c-0932-43e2-8e69-c861a22d8cff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt' ,quiet=True)\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords',quiet=True)\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9c1994fc",
      "metadata": {
        "id": "9c1994fc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "labelled_df = pd.read_csv(\"clean_label.csv\", encoding='utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5443b20",
      "metadata": {
        "id": "e5443b20"
      },
      "source": [
        "# Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21b31e89",
      "metadata": {
        "id": "21b31e89"
      },
      "source": [
        "## Drop Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5c36c101",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c36c101",
        "outputId": "51eca641-f5bb-4487-fd56-9b441c81faeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8603\n"
          ]
        }
      ],
      "source": [
        "labelled_df = labelled_df.drop_duplicates(subset=['clean_text'])\n",
        "print(len(labelled_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "736cd747",
      "metadata": {
        "id": "736cd747"
      },
      "source": [
        "After applying the drop-duplicates process, the dataset now contains 8,603 remaining entries."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83abc775",
      "metadata": {
        "id": "83abc775"
      },
      "source": [
        "## Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "229bfd91",
      "metadata": {
        "id": "229bfd91"
      },
      "outputs": [],
      "source": [
        "def clean_alpha_numeric(text):\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "    text = re.sub(r'[\\u200B-\\u200D\\uFEFF]', '', text).lower()\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a31b2c56",
      "metadata": {
        "id": "a31b2c56"
      },
      "source": [
        "The `clean_alpha_numeric()` function cleans each text entry by removing zero-width characters (in case of encoding errors), converting the text to lowercase, normalizing whitespace, and trimming unnecessary spaces. Missing values are returned unchanged."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a4b5576e",
      "metadata": {
        "id": "a4b5576e"
      },
      "outputs": [],
      "source": [
        "labelled_df['clean_tokens'] = labelled_df['clean_text'].apply(clean_alpha_numeric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c9c1701a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "c9c1701a",
        "outputId": "5a53fd12-12d0-4211-ea18-f49439e2daaa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bandung mau di gimanain juga teteep estetik anjit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>plis pulang sekarang!! dapat info dari sodara ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadar enggak, demo kita sekarang sudah melence...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>guys kita fokus sama dpr saja kalo kalian nger...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ini kapan ya damainya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ada apa dengan negara yang kucintai ini?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>pak soekarno lihat negaramu pak..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>agustus kali ini kacau banget ya....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>gays plis jangan begini kita marah tapi jangan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>loh ini kan jalan tol ya , kok dibakar yang ru...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0    bandung mau di gimanain juga teteep estetik anjit\n",
              "1    plis pulang sekarang!! dapat info dari sodara ...\n",
              "2    sadar enggak, demo kita sekarang sudah melence...\n",
              "3    guys kita fokus sama dpr saja kalo kalian nger...\n",
              "4                                ini kapan ya damainya\n",
              "5             ada apa dengan negara yang kucintai ini?\n",
              "6                    pak soekarno lihat negaramu pak..\n",
              "7                 agustus kali ini kacau banget ya....\n",
              "8    gays plis jangan begini kita marah tapi jangan...\n",
              "9    loh ini kan jalan tol ya , kok dibakar yang ru...\n",
              "Name: clean_tokens, dtype: object"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labelled_df['clean_tokens'].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e5df314",
      "metadata": {
        "id": "8e5df314"
      },
      "source": [
        "# Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6303418f",
      "metadata": {
        "id": "6303418f"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5a49a561",
      "metadata": {
        "id": "5a49a561"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    labelled_df[\"clean_tokens\"], labelled_df[\"classification\"], test_size=0.15, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cba10c7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cba10c7a",
        "outputId": "c3823715-8a3d-45dd-90a7-2e3539945bde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 7312  | Test: 1291\n"
          ]
        }
      ],
      "source": [
        "print(\"Train:\", len(X_train), \" | Test:\", len(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26f453db",
      "metadata": {
        "id": "26f453db"
      },
      "source": [
        "# Feature Extraction for Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16024aec",
      "metadata": {
        "id": "16024aec"
      },
      "source": [
        "## Fast Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4b38662f",
      "metadata": {
        "id": "4b38662f"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1855fb9a",
      "metadata": {
        "id": "1855fb9a"
      },
      "outputs": [],
      "source": [
        "X_train_tokens = X_train.apply(word_tokenize)\n",
        "X_test_tokens = X_test.apply(word_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ab0e340",
      "metadata": {
        "id": "8ab0e340"
      },
      "outputs": [],
      "source": [
        "def sent2vec_fasttext(tokens):\n",
        "    vectors = [model_fasttext.get_word_vector(w) for w in tokens]\n",
        "\n",
        "    if len(vectors) == 0:\n",
        "        return np.zeros((model_fasttext.get_dimension(),), dtype=np.float32)\n",
        "\n",
        "    return np.mean(vectors, axis=0).astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c93fe5d",
      "metadata": {
        "id": "0c93fe5d",
        "outputId": "fd62e4e1-3fac-451f-93a3-4ef2d6ef2c0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FastText shapes: (7312, 300) (1291, 300)\n"
          ]
        }
      ],
      "source": [
        "X_train_ft = np.vstack([sent2vec_fasttext(t) for t in X_train_tokens])\n",
        "X_test_ft  = np.vstack([sent2vec_fasttext(t) for t in X_test_tokens])\n",
        "\n",
        "print(\"FastText shapes:\", X_train_ft.shape, X_test_ft.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6f89d4a",
      "metadata": {
        "id": "d6f89d4a"
      },
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "KalVbY1LP7jT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KalVbY1LP7jT",
        "outputId": "de047186-ce62-486d-d6fa-08805f25a6a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install Sastrawi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c2940469",
      "metadata": {
        "id": "c2940469"
      },
      "outputs": [],
      "source": [
        "from multiprocessing import Pool, cpu_count\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from nltk.corpus import stopwords\n",
        "from functools import lru_cache\n",
        "\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "21f99228",
      "metadata": {
        "id": "21f99228"
      },
      "outputs": [],
      "source": [
        "custom_stopwords = {\n",
        "    'ya','yg','yang','aja','sih','nih','loh','kok','kan','pun','lah','nya','pake','punya','trus','sampe','biar','sma','sm',\n",
        "    'kayak','gitu','gini','jadi','udah','sudah','udh','belum','blum','aq','jg','jd','tau','dgn','krn','karna','gara',\n",
        "    'iya','oh','eh','deh','mah','si','dong','toh','bun','sya','sy','kalo','klo','tp','ku','tpi','gimana','pa',\n",
        "    'bunda','bund','sist','gan','ibu','ayah','suami','istri','anak','ortu','orangtua','teman','tmn','dlu','dy','gtu',\n",
        "    'hari','malam','pagi','siang','besok','kemarin','tadi','sana','sini','situ','daerah','tempat','rumah','kampung','banget',\n",
        "    'aku','kamu','dia','kami','kita','mereka','saya','diriku','diri','pernah','lagi','untk','nb','lg','tdk','bikin','kali',\n",
        "    'jdi','rb','dr','ak','blm','liat','tuh','krna','jt','thn','lgi','th','yah','dg','dah','ny','kk','jga','pdhl','apapun',\n",
        "    'jarang','juta','dn',\n",
        "\n",
        "    'rt', 'ttp', 'sihh', 'udh', 'udh', 'yaaa', 'yaa', 'yaah', 'yaaah',\n",
        "    'min', 'admin', 'kak', 'bro', 'sis',\n",
        "    'hehe', 'huhu', 'haha', 'wkwk', 'wkwkwk', 'wkwwk',\n",
        "    'yaaampun', 'ampun',\n",
        "    'pls', 'please',\n",
        "    'dll', 'dst',\n",
        "    'mah', 'lahh', 'loh', 'yaampun',\n",
        "}\n",
        "\n",
        "nltk_stopwords = set(stopwords.words('indonesian'))\n",
        "all_stopwords = custom_stopwords.union(nltk_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "bbc79056",
      "metadata": {
        "id": "bbc79056"
      },
      "outputs": [],
      "source": [
        "normalization_map = {\n",
        "    \"ga\": \"gak\",\n",
        "    \"g\": \"gak\",\n",
        "    \"gk\": \"gak\",\n",
        "    \"gak\": \"gak\",\n",
        "    \"gaaa\": \"gak\",\n",
        "    \"nggak\": \"gak\",\n",
        "    \"ngga\": \"gak\",\n",
        "    \"nggaaa\": \"gak\",\n",
        "\n",
        "    \"bgt\": \"banget\",\n",
        "    \"bget\": \"banget\",\n",
        "    \"bgttt\": \"banget\",\n",
        "    \"bngt\": \"banget\",\n",
        "\n",
        "    \"sm\": \"sama\",\n",
        "    \"sama2\": \"sama\",\n",
        "\n",
        "    \"dgn\": \"dengan\",\n",
        "    \"dgnn\": \"dengan\",\n",
        "\n",
        "    \"krn\": \"karena\",\n",
        "    \"krna\": \"karena\",\n",
        "\n",
        "    \"tp\": \"tapi\",\n",
        "    \"tpi\": \"tapi\",\n",
        "\n",
        "    \"jg\": \"juga\",\n",
        "    \"jga\": \"juga\",\n",
        "\n",
        "    \"udh\": \"sudah\",\n",
        "    \"udhh\": \"sudah\",\n",
        "\n",
        "    \"blm\": \"belum\",\n",
        "    \"blm2\": \"belum\",\n",
        "\n",
        "    \"skrg\": \"sekarang\",\n",
        "    \"skg\": \"sekarang\",\n",
        "\n",
        "    \"btw\": \"ngomong-ngomong\",\n",
        "\n",
        "    \"pdhl\": \"padahal\",\n",
        "    \"pdahal\": \"padahal\",\n",
        "\n",
        "    \"rmh\": \"rumah\",\n",
        "    \"rmah\": \"rumah\",\n",
        "\n",
        "    \"org\": \"orang\",\n",
        "    \"orang2\": \"orang\",\n",
        "\n",
        "    \"ank\": \"anak\",\n",
        "    \"anak2\": \"anak\",\n",
        "\n",
        "    \"duit\": \"uang\",\n",
        "    \"duwit\": \"uang\",\n",
        "\n",
        "    \"cewe\": \"perempuan\",\n",
        "    \"cewe2\": \"perempuan\",\n",
        "    \"cowo\": \"laki-laki\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e727a330",
      "metadata": {
        "id": "e727a330"
      },
      "outputs": [],
      "source": [
        "@lru_cache(maxsize=50000)\n",
        "def cached_stem(word):\n",
        "    return stemmer.stem(word)\n",
        "\n",
        "def process_single_document(text):\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "\n",
        "    text = text.replace('#', '')\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    if not text: return \"\"\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    final_tokens = []\n",
        "    for token in tokens:\n",
        "        token = normalization_map.get(token, token)\n",
        "        if token in all_stopwords or len(token) < 2:\n",
        "            continue\n",
        "\n",
        "        if not token.isdigit():\n",
        "            token = cached_stem(token)\n",
        "\n",
        "        if len(token) > 1:\n",
        "            final_tokens.append(token)\n",
        "\n",
        "    return \" \".join(final_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c36946d9",
      "metadata": {
        "id": "c36946d9"
      },
      "source": [
        "The `process_single_document()` function cleans and normalizes text by removing hashtags, numbers, and stopwords. It then tokenizes, applies normalization and stemming, filters short tokens, and returns the processed text. Non-string inputs are converted to strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "dad5a6d7",
      "metadata": {
        "id": "dad5a6d7"
      },
      "outputs": [],
      "source": [
        "def preprocess_optimized(texts, n_jobs=None):\n",
        "    if n_jobs is None:\n",
        "        n_jobs = max(1, cpu_count() - 1)\n",
        "\n",
        "    print(f\"Mulai preprocessing dengan {n_jobs} CPU cores...\")\n",
        "\n",
        "    with Pool(processes=n_jobs) as pool:\n",
        "        clean_texts = pool.map(process_single_document, texts, chunksize=100)\n",
        "\n",
        "    print(\"Selesai!\")\n",
        "    return clean_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2d4ac7a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d4ac7a1",
        "outputId": "af3c2180-9c59-47d7-cca6-edd85cb17263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mulai preprocessing dengan 1 CPU cores...\n",
            "Selesai!\n",
            "Mulai preprocessing dengan 1 CPU cores...\n",
            "Selesai!\n"
          ]
        }
      ],
      "source": [
        "X_train_clean = preprocess_optimized(X_train)\n",
        "X_test_clean  = preprocess_optimized(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2l9omEv_kRMh",
      "metadata": {
        "id": "2l9omEv_kRMh"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=7000,\n",
        "    ngram_range=(1, 2),\n",
        "    stop_words=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "AQgsjLY4kSdA",
      "metadata": {
        "id": "AQgsjLY4kSdA"
      },
      "outputs": [],
      "source": [
        "X_train_tfidf = tfidf.fit_transform(X_train_clean)\n",
        "X_test_tfidf = tfidf.transform(X_test_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "-fo5yOMykUB4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fo5yOMykUB4",
        "outputId": "448d15b6-f798-43a3-d36d-765957fb8c11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== TF-IDF =====\n",
            "Shape (train): (7312, 7000)\n",
            "Number of Unique Words: 7000\n",
            "List of Vocab: ['mahasiswa', 'demo', 'rusuh', 'polisi', 'jalan', 'tugas', 'keluarga', 'sana', 'rugi', 'rakyat', 'beras', 'langka', 'depan', 'mahasiswa demo', 'demo rusuh', 'rusuh polisi', 'polisi jalan', 'jalan tugas', 'tugas keluarga', 'rugi rakyat']\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n===== TF-IDF =====\")\n",
        "print(\"Shape (train):\", X_train_tfidf.shape)\n",
        "print(\"Number of Unique Words:\", len(tfidf.vocabulary_))\n",
        "print(\"List of Vocab:\", list(tfidf.vocabulary_.keys())[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Si6XTfrQCvD4",
      "metadata": {
        "id": "Si6XTfrQCvD4"
      },
      "source": [
        "The TF-IDF matrix has a shape of (7312, 7000), meaning 7,312 documents are represented using 7,000 unique terms. The vocabulary includes key unigrams and bigrams such as 'mahasiswa', 'demo', and 'rusuh polisi', reflecting important patterns in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "178c15e8",
      "metadata": {
        "id": "178c15e8"
      },
      "source": [
        "# Modeling - Fast Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "025cb5c7",
      "metadata": {
        "id": "025cb5c7"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "from sklearn.model_selection import (\n",
        "    RandomizedSearchCV,\n",
        "    StratifiedKFold\n",
        ")\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcd02ae1",
      "metadata": {
        "id": "bcd02ae1"
      },
      "outputs": [],
      "source": [
        "def run_ml_experiment(X_train, y_train, X_test, y_test,\n",
        "                      model_type,\n",
        "                      representation_name=\"Model\",\n",
        "                      n_iter=10,\n",
        "                      cv=4,\n",
        "                      use_class_weight=False,\n",
        "                      random_state=42,\n",
        "                      use_tuning=False,\n",
        "                      cache_dir=\"saved_models_2_class\"):\n",
        "\n",
        "    if not os.path.exists(cache_dir):\n",
        "        os.makedirs(cache_dir)\n",
        "\n",
        "    balance_str = \"balanced\" if use_class_weight else \"none\"\n",
        "    model_type_str = model_type.upper()\n",
        "\n",
        "    safe_rep_name = representation_name.replace(\" \", \"_\")\n",
        "    filename = f\"{model_type_str}_{safe_rep_name}_Tuning{use_tuning}_{balance_str}.pkl\"\n",
        "    filepath = os.path.join(cache_dir, filename)\n",
        "\n",
        "    print(f\"Experiment: {representation_name} + {model_type_str} ({balance_str})\")\n",
        "\n",
        "    best_model = None\n",
        "    best_params = None\n",
        "    best_cv_score = None\n",
        "    tuning_time = 0\n",
        "    model_name = \"\"\n",
        "    balance_status_return = \"Class Weight\" if use_class_weight else \"None\"\n",
        "\n",
        "    if os.path.exists(filepath):\n",
        "        print(f\"Found cached model at: {filepath}\")\n",
        "        print(\"   Loading model from pickle... (Skipping training)\")\n",
        "\n",
        "        try:\n",
        "            with open(filepath, 'rb') as f:\n",
        "                cached_data = pickle.load(f)\n",
        "\n",
        "            # Ambil data penting dari pickle\n",
        "            best_model = cached_data['best_model']\n",
        "            best_params = cached_data['best_params']\n",
        "            best_cv_score = cached_data['best_cv_score_f1_macro']\n",
        "            tuning_time = cached_data['tuning_time_seconds']\n",
        "            model_name = cached_data['model_name']\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading pickle ({e}). Will re-train model.\")\n",
        "            os.remove(filepath)\n",
        "\n",
        "    if best_model is None:\n",
        "        print(\"No cache found. Starting training...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        class_weight_param = 'balanced' if use_class_weight else None\n",
        "\n",
        "        if model_type.lower() == \"svm\":\n",
        "            model_name = \"Support Vector Machine\"\n",
        "            model = SVC(C=1.0, kernel=\"rbf\", gamma=\"scale\", probability=True,\n",
        "                        random_state=random_state, class_weight=class_weight_param)\n",
        "            param_dist = {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"], \"gamma\": [\"scale\", \"auto\"]}\n",
        "\n",
        "        elif model_type.lower() == \"rf\":\n",
        "            model_name = \"Random Forest\"\n",
        "            model = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2,\n",
        "                                           random_state=random_state, n_jobs=-1, class_weight=class_weight_param)\n",
        "            param_dist = {\"n_estimators\": [50, 100, 150], \"max_depth\": [None, 3, 5, 10], \"min_samples_split\": [2, 5, 10]}\n",
        "\n",
        "        elif model_type.lower() == \"dt\":\n",
        "            model_name = \"Decision Tree\"\n",
        "            model = DecisionTreeClassifier(criterion=\"gini\", max_depth=None, min_samples_split=2,\n",
        "                                           random_state=random_state, class_weight=class_weight_param)\n",
        "            param_dist = {\"max_depth\": [None, 3, 5, 10], \"min_samples_split\": [2, 5, 10], \"criterion\": [\"gini\", \"entropy\"]}\n",
        "\n",
        "        elif model_type.lower() == \"xgb\":\n",
        "            model_name = \"XGBoost\"\n",
        "            scale_pos_weight = 1\n",
        "            try:\n",
        "                classes, counts = np.unique(y_train, return_counts=True)\n",
        "                if len(classes) == 2:\n",
        "                    neg = counts.max()\n",
        "                    pos = counts.min()\n",
        "                    if pos > 0: scale_pos_weight = float(neg) / float(pos)\n",
        "            except: pass\n",
        "\n",
        "            model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.01, max_depth=5, subsample=0.8,\n",
        "                                      random_state=random_state, n_jobs=-1, eval_metric=\"logloss\",\n",
        "                                      tree_method=\"hist\", scale_pos_weight=scale_pos_weight)\n",
        "            param_dist = {\"n_estimators\": [50, 100], \"learning_rate\": [0.01, 0.1], \"max_depth\": [3, 5]}\n",
        "        else:\n",
        "            raise ValueError(\"Choose model_type = 'svm', 'rf', 'dt', or 'xgb'\")\n",
        "\n",
        "        if not use_tuning:\n",
        "            model.fit(X_train, y_train)\n",
        "            best_model = model\n",
        "            best_params = getattr(model, \"get_params\", lambda: {})()\n",
        "            print(f\"Fitted {model_name} with default parameters.\")\n",
        "        else:\n",
        "            stratified_kfold = StratifiedKFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
        "            random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist,\n",
        "                                               n_iter=n_iter, cv=stratified_kfold, verbose=1,\n",
        "                                               random_state=random_state, n_jobs=-1, scoring=\"f1_macro\")\n",
        "            random_search.fit(X_train, y_train)\n",
        "            best_model = random_search.best_estimator_\n",
        "            best_cv_score = random_search.best_score_\n",
        "            best_params = random_search.best_params_\n",
        "            print(f\"Best CV F1-Macro: {best_cv_score:.4f}\")\n",
        "\n",
        "        tuning_time = time.time() - start_time\n",
        "        print(f\"Training done in {tuning_time:.2f} seconds.\")\n",
        "\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    test_acc = accuracy_score(y_test, y_pred)\n",
        "    test_report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    test_cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nEvaluation on TEST SET\")\n",
        "    print(f\"Accuracy: {test_acc:.4f}\")\n",
        "    if \"macro avg\" in test_report:\n",
        "        print(f\"F1-Macro: {test_report['macro avg']['f1-score']:.4f}\")\n",
        "    else:\n",
        "        print(\"F1-Macro: (not available)\")\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    experiment = {\n",
        "        \"representation_name\": representation_name,\n",
        "        \"model_name\": model_name,\n",
        "        \"balance_strategy\": balance_status_return,\n",
        "        \"best_model\": best_model,\n",
        "        \"best_cv_score_f1_macro\": best_cv_score,\n",
        "        \"best_params\": best_params,\n",
        "        \"test_accuracy\": test_acc,\n",
        "        \"test_f1_macro\": test_report.get(\"macro avg\", {}).get(\"f1-score\", None),\n",
        "        \"test_classification_report_dict\": test_report,\n",
        "        \"test_confusion_matrix\": test_cm,\n",
        "        \"tuning_time_seconds\": tuning_time,\n",
        "        \"tuning\": use_tuning\n",
        "    }\n",
        "\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"Saving model to {filepath} ...\")\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(experiment, f)\n",
        "    else:\n",
        "        print(\"Model loaded from cache, no overwrite needed.\")\n",
        "\n",
        "    return experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a08a379",
      "metadata": {
        "id": "3a08a379"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88fb1e31",
      "metadata": {
        "id": "88fb1e31"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da85e439",
      "metadata": {
        "id": "da85e439",
        "outputId": "36e3954a-f498-4476-a1db-6152f9e828c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: Model + SVM (none)\n",
            "Found cached model at: saved_models_2_class\\SVM_Model_TuningFalse_none.pkl\n",
            "   Loading model from pickle... (Skipping training)\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9775\n",
            "F1-Macro: 0.4943\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.00      0.00      0.00        27\n",
            "  NON_BUZZER       0.98      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.98      1291\n",
            "   macro avg       0.49      0.50      0.49      1291\n",
            "weighted avg       0.96      0.98      0.97      1291\n",
            "\n",
            "Model loaded from cache, no overwrite needed.\n"
          ]
        }
      ],
      "source": [
        "exp_svm = run_ml_experiment(X_train_ft, y_train, X_test_ft, y_test, \"svm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "407ed2e9",
      "metadata": {
        "id": "407ed2e9"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cc646e0",
      "metadata": {
        "id": "6cc646e0",
        "outputId": "56c5ddfc-7aec-4084-be93-9368ebd862b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: Model + RF (none)\n",
            "Found cached model at: saved_models_2_class\\RF_Model_TuningFalse_none.pkl\n",
            "   Loading model from pickle... (Skipping training)\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9837\n",
            "F1-Macro: 0.7121\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.80      0.30      0.43        27\n",
            "  NON_BUZZER       0.99      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.98      1291\n",
            "   macro avg       0.89      0.65      0.71      1291\n",
            "weighted avg       0.98      0.98      0.98      1291\n",
            "\n",
            "Model loaded from cache, no overwrite needed.\n"
          ]
        }
      ],
      "source": [
        "exp_rf  = run_ml_experiment(X_train_ft, y_train, X_test_ft, y_test, \"rf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "774b38bc",
      "metadata": {
        "id": "774b38bc"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "025dbdfd",
      "metadata": {
        "id": "025dbdfd",
        "outputId": "ac6f1100-f220-499d-bd20-309c3b004a44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: Model + DT (none)\n",
            "Found cached model at: saved_models_2_class\\DT_Model_TuningFalse_none.pkl\n",
            "   Loading model from pickle... (Skipping training)\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9582\n",
            "F1-Macro: 0.6142\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.20      0.33      0.25        27\n",
            "  NON_BUZZER       0.99      0.97      0.98      1264\n",
            "\n",
            "    accuracy                           0.96      1291\n",
            "   macro avg       0.59      0.65      0.61      1291\n",
            "weighted avg       0.97      0.96      0.96      1291\n",
            "\n",
            "Model loaded from cache, no overwrite needed.\n"
          ]
        }
      ],
      "source": [
        "exp_dt  = run_ml_experiment(X_train_ft, y_train, X_test_ft, y_test, \"dt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df4ebbe7",
      "metadata": {
        "id": "df4ebbe7"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "6271697b",
      "metadata": {
        "id": "6271697b"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_test_enc = le.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3b39d1a",
      "metadata": {
        "id": "f3b39d1a",
        "outputId": "1f95e03e-6bd4-45b7-eb7f-9b3b6fe67748"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: Model + XGB (none)\n",
            "Found cached model at: saved_models_2_class\\XGB_Model_TuningFalse_none.pkl\n",
            "   Loading model from pickle... (Skipping training)\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9791\n",
            "F1-Macro: 0.4947\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        27\n",
            "           1       0.98      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.98      1291\n",
            "   macro avg       0.49      0.50      0.49      1291\n",
            "weighted avg       0.96      0.98      0.97      1291\n",
            "\n",
            "Model loaded from cache, no overwrite needed.\n"
          ]
        }
      ],
      "source": [
        "exp_xgb = run_ml_experiment(X_train_ft, y_train_enc, X_test_ft, y_test_enc, \"xgb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "310efa6c",
      "metadata": {
        "id": "310efa6c"
      },
      "source": [
        "## Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02de3bd5",
      "metadata": {
        "id": "02de3bd5"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d21f77e",
      "metadata": {
        "id": "3d21f77e",
        "outputId": "5ae18965-d163-4455-bc24-6f7fd03bfb78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: Model + SVM (none)\n",
            "Found cached model at: saved_models_2_class\\SVM_Model_TuningTrue_none.pkl\n",
            "   Loading model from pickle... (Skipping training)\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9853\n",
            "F1-Macro: 0.7753\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.75      0.44      0.56        27\n",
            "  NON_BUZZER       0.99      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.99      1291\n",
            "   macro avg       0.87      0.72      0.78      1291\n",
            "weighted avg       0.98      0.99      0.98      1291\n",
            "\n",
            "Model loaded from cache, no overwrite needed.\n"
          ]
        }
      ],
      "source": [
        "exp_svm_ft = run_ml_experiment(X_train_ft, y_train, X_test_ft, y_test, \"svm\", use_tuning=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "052e60e1",
      "metadata": {
        "id": "052e60e1",
        "outputId": "593f9f70-2753-423f-fadd-c7bfa0696236"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'kernel': 'rbf', 'gamma': 'scale', 'C': 10}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "exp_svm_ft['best_params']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9627b09e",
      "metadata": {
        "id": "9627b09e"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b04576f",
      "metadata": {
        "id": "4b04576f",
        "outputId": "2e1ef5d3-05b8-4b0a-9d27-6753bdd1f05b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: Model + RF (none)\n",
            "Found cached model at: saved_models_2_class\\RF_Model_TuningTrue_none.pkl\n",
            "   Loading model from pickle... (Skipping training)\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9830\n",
            "F1-Macro: 0.6722\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.86      0.22      0.35        27\n",
            "  NON_BUZZER       0.98      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.98      1291\n",
            "   macro avg       0.92      0.61      0.67      1291\n",
            "weighted avg       0.98      0.98      0.98      1291\n",
            "\n",
            "Model loaded from cache, no overwrite needed.\n"
          ]
        }
      ],
      "source": [
        "exp_rf_ft = run_ml_experiment(X_train_ft, y_train, X_test_ft, y_test, \"rf\", use_tuning=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41c01cb3",
      "metadata": {
        "id": "41c01cb3",
        "outputId": "b9c1f7ed-84f0-41ef-8736-229eebf916b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 150, 'min_samples_split': 10, 'max_depth': None}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "exp_rf_ft['best_params']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71114549",
      "metadata": {
        "id": "71114549"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19cd9d86",
      "metadata": {
        "id": "19cd9d86",
        "outputId": "219ac143-74f8-4ecf-ff0f-644c76bf274b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: Model + DT (none)\n",
            "Found cached model at: saved_models_2_class\\DT_Model_TuningTrue_none.pkl\n",
            "   Loading model from pickle... (Skipping training)\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9752\n",
            "F1-Macro: 0.6127\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.33      0.19      0.24        27\n",
            "  NON_BUZZER       0.98      0.99      0.99      1264\n",
            "\n",
            "    accuracy                           0.98      1291\n",
            "   macro avg       0.66      0.59      0.61      1291\n",
            "weighted avg       0.97      0.98      0.97      1291\n",
            "\n",
            "Model loaded from cache, no overwrite needed.\n"
          ]
        }
      ],
      "source": [
        "exp_dt_ft = run_ml_experiment(X_train_ft, y_train, X_test_ft, y_test, \"dt\", use_tuning=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91c651e9",
      "metadata": {
        "id": "91c651e9",
        "outputId": "e9df49af-a774-44d1-c8a7-06aaf2d36a94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'min_samples_split': 2, 'max_depth': 5, 'criterion': 'entropy'}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "exp_dt_ft['best_params']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b286e26f",
      "metadata": {
        "id": "b286e26f"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "521aeefc",
      "metadata": {
        "id": "521aeefc",
        "outputId": "d5f8663e-1b44-4965-cb17-41c7bc0d2e18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: Model + XGB (none)\n",
            "Found cached model at: saved_models_2_class\\XGB_Model_TuningTrue_none.pkl\n",
            "   Loading model from pickle... (Skipping training)\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9845\n",
            "F1-Macro: 0.7020\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.26      0.41        27\n",
            "           1       0.98      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.98      1291\n",
            "   macro avg       0.99      0.63      0.70      1291\n",
            "weighted avg       0.98      0.98      0.98      1291\n",
            "\n",
            "Model loaded from cache, no overwrite needed.\n"
          ]
        }
      ],
      "source": [
        "exp_xgb_ft = run_ml_experiment(X_train_ft, y_train_enc, X_test_ft, y_test_enc, \"xgb\", use_tuning=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c5ace1",
      "metadata": {
        "id": "c0c5ace1",
        "outputId": "d7660479-8331-4fb2-e48e-b93364049d9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "exp_xgb_ft['best_params']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f71d0fa",
      "metadata": {
        "id": "9f71d0fa"
      },
      "source": [
        "## Class Weight"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7043ea0e",
      "metadata": {
        "id": "7043ea0e"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34b8c526",
      "metadata": {
        "id": "34b8c526",
        "outputId": "3a07d9a9-739a-4c31-e78d-c6004c1a0cb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: Model + SVM (balanced)\n",
            "Found cached model at: saved_models_2_class\\SVM_Model_TuningFalse_balanced.pkl\n",
            "   Loading model from pickle... (Skipping training)\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9342\n",
            "F1-Macro: 0.6427\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.20      0.74      0.32        27\n",
            "  NON_BUZZER       0.99      0.94      0.97      1264\n",
            "\n",
            "    accuracy                           0.93      1291\n",
            "   macro avg       0.60      0.84      0.64      1291\n",
            "weighted avg       0.98      0.93      0.95      1291\n",
            "\n",
            "Model loaded from cache, no overwrite needed.\n"
          ]
        }
      ],
      "source": [
        "exp_svm_cw = run_ml_experiment(X_train_ft, y_train, X_test_ft, y_test, \"svm\", use_class_weight=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "874854d9",
      "metadata": {
        "id": "874854d9"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f36416f",
      "metadata": {
        "id": "2f36416f",
        "outputId": "87900c50-577c-4774-ec5a-54d5b1b26254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: Model + RF (balanced)\n",
            "Found cached model at: saved_models_2_class\\RF_Model_TuningFalse_balanced.pkl\n",
            "   Loading model from pickle... (Skipping training)\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9837\n",
            "F1-Macro: 0.6777\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       1.00      0.22      0.36        27\n",
            "  NON_BUZZER       0.98      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.98      1291\n",
            "   macro avg       0.99      0.61      0.68      1291\n",
            "weighted avg       0.98      0.98      0.98      1291\n",
            "\n",
            "Model loaded from cache, no overwrite needed.\n"
          ]
        }
      ],
      "source": [
        "exp_rf_cw  = run_ml_experiment(X_train_ft, y_train, X_test_ft, y_test, \"rf\", use_class_weight=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff5993fb",
      "metadata": {
        "id": "ff5993fb"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acfe0afa",
      "metadata": {
        "id": "acfe0afa",
        "outputId": "72a31e0b-d1e2-418b-8753-cb9f661fd448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: Model + DT (balanced)\n",
            "Found cached model at: saved_models_2_class\\DT_Model_TuningFalse_balanced.pkl\n",
            "   Loading model from pickle... (Skipping training)\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9729\n",
            "F1-Macro: 0.6499\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.33      0.30      0.31        27\n",
            "  NON_BUZZER       0.99      0.99      0.99      1264\n",
            "\n",
            "    accuracy                           0.97      1291\n",
            "   macro avg       0.66      0.64      0.65      1291\n",
            "weighted avg       0.97      0.97      0.97      1291\n",
            "\n",
            "Model loaded from cache, no overwrite needed.\n"
          ]
        }
      ],
      "source": [
        "exp_dt_cw  = run_ml_experiment(X_train_ft, y_train, X_test_ft, y_test, \"dt\", use_class_weight=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "194c9ef5",
      "metadata": {
        "id": "194c9ef5"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e44b493",
      "metadata": {
        "id": "5e44b493",
        "outputId": "38c34300-28a2-49b0-aef5-acefb343dba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: Model + XGB (balanced)\n",
            "Found cached model at: saved_models_2_class\\XGB_Model_TuningFalse_balanced.pkl\n",
            "   Loading model from pickle... (Skipping training)\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9791\n",
            "F1-Macro: 0.4947\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        27\n",
            "           1       0.98      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.98      1291\n",
            "   macro avg       0.49      0.50      0.49      1291\n",
            "weighted avg       0.96      0.98      0.97      1291\n",
            "\n",
            "Model loaded from cache, no overwrite needed.\n"
          ]
        }
      ],
      "source": [
        "exp_xgb_cw = run_ml_experiment(X_train_ft, y_train_enc, X_test_ft, y_test_enc, \"xgb\", use_class_weight=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d9a6241",
      "metadata": {
        "id": "3d9a6241"
      },
      "source": [
        "## Fine Tuning - Class Weight"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7f326e1",
      "metadata": {
        "id": "b7f326e1"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4989b6fb",
      "metadata": {
        "id": "4989b6fb",
        "outputId": "eb6e38b6-65b2-4f41-b8da-0e6dae31b12e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: Model + SVM (balanced)\n",
            "Found cached model at: saved_models_2_class\\SVM_Model_TuningTrue_balanced.pkl\n",
            "   Loading model from pickle... (Skipping training)\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9737\n",
            "F1-Macro: 0.7357\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.41      0.59      0.48        27\n",
            "  NON_BUZZER       0.99      0.98      0.99      1264\n",
            "\n",
            "    accuracy                           0.97      1291\n",
            "   macro avg       0.70      0.79      0.74      1291\n",
            "weighted avg       0.98      0.97      0.98      1291\n",
            "\n",
            "Model loaded from cache, no overwrite needed.\n"
          ]
        }
      ],
      "source": [
        "exp_svm_cw_ft = run_ml_experiment(X_train_ft, y_train, X_test_ft, y_test, \"svm\", use_class_weight=True, use_tuning=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca78dc3a",
      "metadata": {
        "id": "ca78dc3a",
        "outputId": "5b941f24-efb4-4c47-d42c-6dc32b389afa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'kernel': 'rbf', 'gamma': 'scale', 'C': 10}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "exp_svm_cw_ft[\"best_params\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d5a2eac",
      "metadata": {
        "id": "5d5a2eac"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3dd13b8",
      "metadata": {
        "id": "e3dd13b8",
        "outputId": "99e050d9-b3f8-409b-ae6c-f650d97dade2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: Model + RF (balanced)\n",
            "Found cached model at: saved_models_2_class\\RF_Model_TuningTrue_balanced.pkl\n",
            "   Loading model from pickle... (Skipping training)\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9845\n",
            "F1-Macro: 0.7580\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.73      0.41      0.52        27\n",
            "  NON_BUZZER       0.99      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.98      1291\n",
            "   macro avg       0.86      0.70      0.76      1291\n",
            "weighted avg       0.98      0.98      0.98      1291\n",
            "\n",
            "Model loaded from cache, no overwrite needed.\n"
          ]
        }
      ],
      "source": [
        "exp_rf_cw_ft = run_ml_experiment(X_train_ft, y_train, X_test_ft, y_test, \"rf\", use_class_weight=True, use_tuning=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d8f7493",
      "metadata": {
        "id": "5d8f7493",
        "outputId": "bcfa0a08-b32f-458e-a50e-bd6f6885a954"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 50, 'min_samples_split': 5, 'max_depth': 10}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "exp_rf_cw_ft[\"best_params\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d512ecb",
      "metadata": {
        "id": "8d512ecb"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46acfd6c",
      "metadata": {
        "id": "46acfd6c",
        "outputId": "a3bd3710-5f78-4bdf-9149-2399bfca8705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: Model + DT (balanced)\n",
            "Found cached model at: saved_models_2_class\\DT_Model_TuningTrue_balanced.pkl\n",
            "   Loading model from pickle... (Skipping training)\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9729\n",
            "F1-Macro: 0.6499\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.33      0.30      0.31        27\n",
            "  NON_BUZZER       0.99      0.99      0.99      1264\n",
            "\n",
            "    accuracy                           0.97      1291\n",
            "   macro avg       0.66      0.64      0.65      1291\n",
            "weighted avg       0.97      0.97      0.97      1291\n",
            "\n",
            "Model loaded from cache, no overwrite needed.\n"
          ]
        }
      ],
      "source": [
        "exp_dt_cw_ft = run_ml_experiment(X_train_ft, y_train, X_test_ft, y_test, \"dt\", use_class_weight=True, use_tuning=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c508e9d",
      "metadata": {
        "id": "1c508e9d",
        "outputId": "084b40d5-fe54-4ec0-bdbb-9edea40eb8a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'min_samples_split': 2, 'max_depth': None, 'criterion': 'gini'}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "exp_dt_cw_ft[\"best_params\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c7eafef",
      "metadata": {
        "id": "5c7eafef"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f762d11c",
      "metadata": {
        "id": "f762d11c",
        "outputId": "e8d1bde2-771f-45bd-830e-633a69dbc1f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: Model + XGB (balanced)\n",
            "Found cached model at: saved_models_2_class\\XGB_Model_TuningTrue_balanced.pkl\n",
            "   Loading model from pickle... (Skipping training)\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9845\n",
            "F1-Macro: 0.7020\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.26      0.41        27\n",
            "           1       0.98      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.98      1291\n",
            "   macro avg       0.99      0.63      0.70      1291\n",
            "weighted avg       0.98      0.98      0.98      1291\n",
            "\n",
            "Model loaded from cache, no overwrite needed.\n"
          ]
        }
      ],
      "source": [
        "exp_xgb_cw_ft = run_ml_experiment(X_train_ft, y_train_enc, X_test_ft, y_test_enc, \"xgb\", use_class_weight=True, use_tuning=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ac837fa",
      "metadata": {
        "id": "4ac837fa",
        "outputId": "d4fa59cf-8c22-4e98-e0e2-e101d0d986e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1}"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "exp_xgb_cw_ft[\"best_params\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b8d310a",
      "metadata": {
        "id": "4b8d310a"
      },
      "source": [
        "## Table Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "d4badb9a",
      "metadata": {
        "id": "d4badb9a"
      },
      "outputs": [],
      "source": [
        "def create_comparison_table(experiment_results_list):\n",
        "    rows = []\n",
        "\n",
        "    for exp in experiment_results_list:\n",
        "        report = exp.get('test_classification_report_dict', {})\n",
        "        buzzer_metrics = report.get('0') or report.get('BUZZER') or {}\n",
        "\n",
        "        row = {\n",
        "            'Model': exp['model_name'],\n",
        "            'Balance Strategy': exp['balance_strategy'],\n",
        "            'Tuning': exp['tuning'],\n",
        "            'Precision (Buzzer)': buzzer_metrics.get('precision', 0),\n",
        "            'Recall (Buzzer)': buzzer_metrics.get('recall', 0),\n",
        "            'F1 Score (Buzzer)': buzzer_metrics.get('f1-score', 0),\n",
        "            'F1 Score (Macro)': exp['test_f1_macro']\n",
        "        }\n",
        "        rows.append(row)\n",
        "\n",
        "    df_comparison = pd.DataFrame(rows)\n",
        "\n",
        "    df_comparison = df_comparison.sort_values(by='F1 Score (Macro)', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    return df_comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73f37a09",
      "metadata": {
        "id": "73f37a09"
      },
      "outputs": [],
      "source": [
        "all_experiments = [exp_svm, exp_svm_cw, exp_svm_cw_ft, exp_svm_ft,\n",
        "                   exp_rf, exp_rf_cw, exp_rf_cw_ft, exp_rf_ft,\n",
        "                   exp_dt_ft, exp_dt_cw, exp_dt_cw_ft, exp_dt_ft,\n",
        "                   exp_xgb, exp_xgb_cw, exp_xgb_cw_ft, exp_xgb_ft]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac6878ab",
      "metadata": {
        "id": "ac6878ab",
        "outputId": "e25f91f7-aca5-4df1-fdca-04ab67b44faf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== FINAL COMPARISON TABLE - FAST TEXT ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Balance Strategy</th>\n",
              "      <th>Tuning</th>\n",
              "      <th>Precision (Buzzer)</th>\n",
              "      <th>Recall (Buzzer)</th>\n",
              "      <th>F1 Score (Buzzer)</th>\n",
              "      <th>F1 Score (Macro)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Support Vector Machine</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.444</td>\n",
              "      <td>0.558</td>\n",
              "      <td>0.775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>Class Weight</td>\n",
              "      <td>True</td>\n",
              "      <td>0.733</td>\n",
              "      <td>0.407</td>\n",
              "      <td>0.524</td>\n",
              "      <td>0.758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Support Vector Machine</td>\n",
              "      <td>Class Weight</td>\n",
              "      <td>True</td>\n",
              "      <td>0.410</td>\n",
              "      <td>0.593</td>\n",
              "      <td>0.485</td>\n",
              "      <td>0.736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.296</td>\n",
              "      <td>0.432</td>\n",
              "      <td>0.712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.259</td>\n",
              "      <td>0.412</td>\n",
              "      <td>0.702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>Class Weight</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.259</td>\n",
              "      <td>0.412</td>\n",
              "      <td>0.702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>Class Weight</td>\n",
              "      <td>False</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.222</td>\n",
              "      <td>0.364</td>\n",
              "      <td>0.678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>0.857</td>\n",
              "      <td>0.222</td>\n",
              "      <td>0.353</td>\n",
              "      <td>0.672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>Class Weight</td>\n",
              "      <td>False</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0.296</td>\n",
              "      <td>0.314</td>\n",
              "      <td>0.650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>Class Weight</td>\n",
              "      <td>True</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0.296</td>\n",
              "      <td>0.314</td>\n",
              "      <td>0.650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Support Vector Machine</td>\n",
              "      <td>Class Weight</td>\n",
              "      <td>False</td>\n",
              "      <td>0.204</td>\n",
              "      <td>0.741</td>\n",
              "      <td>0.320</td>\n",
              "      <td>0.643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0.185</td>\n",
              "      <td>0.238</td>\n",
              "      <td>0.613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0.185</td>\n",
              "      <td>0.238</td>\n",
              "      <td>0.613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>Class Weight</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Support Vector Machine</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.494</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Model Balance Strategy  Tuning  Precision (Buzzer)  \\\n",
              "0   Support Vector Machine             None    True               0.750   \n",
              "1            Random Forest     Class Weight    True               0.733   \n",
              "2   Support Vector Machine     Class Weight    True               0.410   \n",
              "3            Random Forest             None   False               0.800   \n",
              "4                  XGBoost             None    True               1.000   \n",
              "5                  XGBoost     Class Weight    True               1.000   \n",
              "6            Random Forest     Class Weight   False               1.000   \n",
              "7            Random Forest             None    True               0.857   \n",
              "8            Decision Tree     Class Weight   False               0.333   \n",
              "9            Decision Tree     Class Weight    True               0.333   \n",
              "10  Support Vector Machine     Class Weight   False               0.204   \n",
              "11           Decision Tree             None    True               0.333   \n",
              "12           Decision Tree             None    True               0.333   \n",
              "13                 XGBoost     Class Weight   False               0.000   \n",
              "14                 XGBoost             None   False               0.000   \n",
              "15  Support Vector Machine             None   False               0.000   \n",
              "\n",
              "    Recall (Buzzer)  F1 Score (Buzzer)  F1 Score (Macro)  \n",
              "0             0.444              0.558             0.775  \n",
              "1             0.407              0.524             0.758  \n",
              "2             0.593              0.485             0.736  \n",
              "3             0.296              0.432             0.712  \n",
              "4             0.259              0.412             0.702  \n",
              "5             0.259              0.412             0.702  \n",
              "6             0.222              0.364             0.678  \n",
              "7             0.222              0.353             0.672  \n",
              "8             0.296              0.314             0.650  \n",
              "9             0.296              0.314             0.650  \n",
              "10            0.741              0.320             0.643  \n",
              "11            0.185              0.238             0.613  \n",
              "12            0.185              0.238             0.613  \n",
              "13            0.000              0.000             0.495  \n",
              "14            0.000              0.000             0.495  \n",
              "15            0.000              0.000             0.494  "
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_result = create_comparison_table(all_experiments)\n",
        "\n",
        "print(\"\\n=== FINAL COMPARISON TABLE - FAST TEXT ===\")\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "df_result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08f52a02",
      "metadata": {
        "id": "08f52a02"
      },
      "source": [
        "The comparison table shows that Support Vector Machine (SVM) with hyperparameter tuning and no class-weighting achieves the best overall performance, with an F1-Macro score of 0.775, the highest among all tested models. This indicates that SVM is the most effective classifier for distinguishing between the two classes using FastText embeddings. This model strikes the best balance of Precision (0.75) and Recall (0.44) in predicting Buzzer class. It shows that while it detects fewer than half of the actual \"Buzzer\", it is highly reliable when it does make a prediction (75% of its predictions are correct).\n",
        "\n",
        "SVM with tuning achieves the highest macro-F1 score because it effectively utilizes FastText’s dense semantic embeddings and benefits from optimized hyperparameters (e.g., C, kernel). These adjustments improve its ability to separate classes in high-dimensional space, outperforming Random Forest, XGBoost, and Decision Tree models.\n",
        "\n",
        "Random Forest and XGBoost also achieve high accuracy, but their macro-recall and macro-F1 scores are consistently lower, suggesting difficulty in balancing performance across both classes, especially the minority class. On the other side, overall Decision Tree models show the weakest performance, which is expected because they tend to overfit on dense text embeddings like FastText.\n",
        "\n",
        "Our comparison table reveals a trade-offs between Precision and Recall. Row 4 and row 6 achieved a perfect Precision (1.0), but this came at the cost of the Recall (~0.22 - 0.26). They missed over 75% of the actual buzzer class, meaning these models are too conservative at predicting \"Buzzer\". On the other hand, applying Class Weight to SVM successfully shifted the focus into the minority class (Buzzer), raising the Recall to 0.593, but this caused the Precision to drop to 0.41."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fx0YeUJqhNf2",
      "metadata": {
        "id": "fx0YeUJqhNf2"
      },
      "source": [
        "# Modeling - TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TwqLhnFxQk3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwqLhnFxQk3f",
        "outputId": "ce9670ef-53da-4cc5-ec55-22ba9d36f4d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  saved_models_tfidf_2_class.zip\n",
            "   creating: saved_models_tfidf_2_class/\n",
            "  inflating: saved_models_tfidf_2_class/DT_TFIDF_Model_TuningFalse_balanced.pkl  \n",
            "  inflating: saved_models_tfidf_2_class/DT_TFIDF_Model_TuningFalse_none.pkl  \n",
            "  inflating: saved_models_tfidf_2_class/DT_TFIDF_Model_TuningTrue_balanced.pkl  \n",
            "  inflating: saved_models_tfidf_2_class/DT_TFIDF_Model_TuningTrue_none.pkl  \n",
            "  inflating: saved_models_tfidf_2_class/RF_TFIDF_Model_TuningFalse_balanced.pkl  \n",
            "  inflating: saved_models_tfidf_2_class/RF_TFIDF_Model_TuningFalse_none.pkl  \n",
            "  inflating: saved_models_tfidf_2_class/RF_TFIDF_Model_TuningTrue_balanced.pkl  \n",
            "  inflating: saved_models_tfidf_2_class/RF_TFIDF_Model_TuningTrue_none.pkl  \n",
            "  inflating: saved_models_tfidf_2_class/SVM_TFIDF_Model_TuningFalse_balanced.pkl  \n",
            "  inflating: saved_models_tfidf_2_class/SVM_TFIDF_Model_TuningFalse_none.pkl  \n",
            "  inflating: saved_models_tfidf_2_class/SVM_TFIDF_Model_TuningTrue_balanced.pkl  \n",
            "  inflating: saved_models_tfidf_2_class/SVM_TFIDF_Model_TuningTrue_none.pkl  \n",
            "  inflating: saved_models_tfidf_2_class/XGB_TFIDF_Model_TuningFalse_balanced.pkl  \n",
            "  inflating: saved_models_tfidf_2_class/XGB_TFIDF_Model_TuningFalse_none.pkl  \n",
            "  inflating: saved_models_tfidf_2_class/XGB_TFIDF_Model_TuningTrue_balanced.pkl  \n",
            "  inflating: saved_models_tfidf_2_class/XGB_TFIDF_Model_TuningTrue_none.pkl  \n"
          ]
        }
      ],
      "source": [
        "!unzip saved_models_tfidf_2_class.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ZOEpRPIThQ1n",
      "metadata": {
        "id": "ZOEpRPIThQ1n"
      },
      "outputs": [],
      "source": [
        "def run_ml_experiment_tfidf(X_train, y_train, X_test, y_test,\n",
        "                      model_type,\n",
        "                      representation_name=\"TFIDF_Model\",\n",
        "                      n_iter=10,\n",
        "                      cv=4,\n",
        "                      use_class_weight=False,\n",
        "                      random_state=42,\n",
        "                      use_tuning=False,\n",
        "                      cache_dir=\"saved_models_tfidf_2_class\"):\n",
        "\n",
        "    if not os.path.exists(cache_dir):\n",
        "        os.makedirs(cache_dir)\n",
        "\n",
        "    balance_str = \"balanced\" if use_class_weight else \"none\"\n",
        "    model_type_str = model_type.upper()\n",
        "\n",
        "    safe_rep_name = representation_name.replace(\" \", \"_\")\n",
        "    filename = f\"{model_type_str}_{safe_rep_name}_Tuning{use_tuning}_{balance_str}.pkl\"\n",
        "    filepath = os.path.join(cache_dir, filename)\n",
        "\n",
        "    print(f\"Experiment: {representation_name} + {model_type_str} ({balance_str})\")\n",
        "\n",
        "    best_model = None\n",
        "    best_params = None\n",
        "    best_cv_score = None\n",
        "    tuning_time = 0\n",
        "    model_name = \"\"\n",
        "    balance_status_return = \"Class Weight\" if use_class_weight else \"None\"\n",
        "\n",
        "    if os.path.exists(filepath):\n",
        "        print(f\"Found cached model at: {filepath}\")\n",
        "        print(\"   Loading model from pickle... (Skipping training)\")\n",
        "\n",
        "        try:\n",
        "            with open(filepath, 'rb') as f:\n",
        "                cached_data = pickle.load(f)\n",
        "\n",
        "            best_model = cached_data['best_model']\n",
        "            best_params = cached_data['best_params']\n",
        "            best_cv_score = cached_data['best_cv_score_f1_macro']\n",
        "            tuning_time = cached_data['tuning_time_seconds']\n",
        "            model_name = cached_data['model_name']\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading pickle ({e}). Will re-train model.\")\n",
        "            os.remove(filepath)\n",
        "\n",
        "    if best_model is None:\n",
        "        print(\"No cache found. Starting training...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        class_weight_param = 'balanced' if use_class_weight else None\n",
        "\n",
        "        if model_type.lower() == \"svm\":\n",
        "            model_name = \"Support Vector Machine\"\n",
        "            model = SVC(C=1.0, kernel=\"rbf\", gamma=\"scale\", probability=True,\n",
        "                        random_state=random_state, class_weight=class_weight_param)\n",
        "            param_dist = {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"], \"gamma\": [\"scale\", \"auto\"]}\n",
        "\n",
        "        elif model_type.lower() == \"rf\":\n",
        "            model_name = \"Random Forest\"\n",
        "            model = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2,\n",
        "                                           random_state=random_state, n_jobs=-1, class_weight=class_weight_param)\n",
        "            param_dist = {\"n_estimators\": [50, 100, 150], \"max_depth\": [None, 3, 5, 10], \"min_samples_split\": [2, 5, 10]}\n",
        "\n",
        "        elif model_type.lower() == \"dt\":\n",
        "            model_name = \"Decision Tree\"\n",
        "            model = DecisionTreeClassifier(criterion=\"gini\", max_depth=None, min_samples_split=2,\n",
        "                                           random_state=random_state, class_weight=class_weight_param)\n",
        "            param_dist = {\"max_depth\": [None, 3, 5, 10], \"min_samples_split\": [2, 5, 10], \"criterion\": [\"gini\", \"entropy\"]}\n",
        "\n",
        "        elif model_type.lower() == \"xgb\":\n",
        "            model_name = \"XGBoost\"\n",
        "            scale_pos_weight = 1\n",
        "            try:\n",
        "                classes, counts = np.unique(y_train, return_counts=True)\n",
        "                if len(classes) == 2:\n",
        "                    neg = counts.max()\n",
        "                    pos = counts.min()\n",
        "                    if pos > 0: scale_pos_weight = float(neg) / float(pos)\n",
        "            except: pass\n",
        "\n",
        "            model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.01, max_depth=5, subsample=0.8,\n",
        "                                      random_state=random_state, n_jobs=-1, eval_metric=\"logloss\",\n",
        "                                      tree_method=\"hist\", scale_pos_weight=scale_pos_weight)\n",
        "            param_dist = {\"n_estimators\": [50, 100], \"learning_rate\": [0.01, 0.1], \"max_depth\": [3, 5]}\n",
        "        else:\n",
        "            raise ValueError(\"Choose model_type = 'svm', 'rf', 'dt', or 'xgb'\")\n",
        "\n",
        "        if not use_tuning:\n",
        "            model.fit(X_train, y_train)\n",
        "            best_model = model\n",
        "            best_params = getattr(model, \"get_params\", lambda: {})()\n",
        "            print(f\"Fitted {model_name} with default parameters.\")\n",
        "        else:\n",
        "            stratified_kfold = StratifiedKFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
        "            random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist,\n",
        "                                               n_iter=n_iter, cv=stratified_kfold, verbose=1,\n",
        "                                               random_state=random_state, n_jobs=-1, scoring=\"f1_macro\")\n",
        "            random_search.fit(X_train, y_train)\n",
        "            best_model = random_search.best_estimator_\n",
        "            best_cv_score = random_search.best_score_\n",
        "            best_params = random_search.best_params_\n",
        "            print(f\"Best CV F1-Macro: {best_cv_score:.4f}\")\n",
        "\n",
        "        tuning_time = time.time() - start_time\n",
        "        print(f\"Training done in {tuning_time:.2f} seconds.\")\n",
        "\n",
        "\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    test_acc = accuracy_score(y_test, y_pred)\n",
        "    test_report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    test_cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nEvaluation on TEST SET\")\n",
        "    print(f\"Accuracy: {test_acc:.4f}\")\n",
        "    if \"macro avg\" in test_report:\n",
        "        print(f\"F1-Macro: {test_report['macro avg']['f1-score']:.4f}\")\n",
        "    else:\n",
        "        print(\"F1-Macro: (not available)\")\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    experiment = {\n",
        "        \"representation_name\": representation_name,\n",
        "        \"model_name\": model_name,\n",
        "        \"balance_strategy\": balance_status_return,\n",
        "        \"best_model\": best_model,\n",
        "        \"best_cv_score_f1_macro\": best_cv_score,\n",
        "        \"best_params\": best_params,\n",
        "        \"test_accuracy\": test_acc,\n",
        "        \"test_f1_macro\": test_report.get(\"macro avg\", {}).get(\"f1-score\", None),\n",
        "        \"test_classification_report_dict\": test_report,\n",
        "        \"test_confusion_matrix\": test_cm,\n",
        "        \"tuning_time_seconds\": tuning_time,\n",
        "        \"tuning\": use_tuning\n",
        "    }\n",
        "\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"Saving model to {filepath} ...\")\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(experiment, f)\n",
        "    else:\n",
        "        print(\"Model loaded from cache, no overwrite needed.\")\n",
        "\n",
        "    return experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IrO8BMW2r6CO",
      "metadata": {
        "id": "IrO8BMW2r6CO"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G2FDUHEbr82D",
      "metadata": {
        "id": "G2FDUHEbr82D"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "6LHBI0SasoTH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LHBI0SasoTH",
        "outputId": "35fdb1ae-6ddf-4ff6-adca-c529b97b0489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: TFIDF_Model + SVM (none)\n",
            "No cache found. Starting training...\n",
            "Fitted Support Vector Machine with default parameters.\n",
            "Training done in 7.59 seconds.\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9861\n",
            "F1-Macro: 0.7715\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.85      0.41      0.55        27\n",
            "  NON_BUZZER       0.99      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.99      1291\n",
            "   macro avg       0.92      0.70      0.77      1291\n",
            "weighted avg       0.98      0.99      0.98      1291\n",
            "\n",
            "Saving model to saved_models_tfidf_2_class/SVM_TFIDF_Model_TuningFalse_none.pkl ...\n"
          ]
        }
      ],
      "source": [
        "exp_svm_tfidf = run_ml_experiment_tfidf(X_train_tfidf, y_train, X_test_tfidf, y_test, \"svm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MPMIKR3Or9ua",
      "metadata": {
        "id": "MPMIKR3Or9ua"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "KNGRGvsJvpfm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNGRGvsJvpfm",
        "outputId": "c04a2f94-75b0-4764-d852-6f08ebc1223d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: TFIDF_Model + RF (none)\n",
            "No cache found. Starting training...\n",
            "Fitted Random Forest with default parameters.\n",
            "Training done in 5.02 seconds.\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9884\n",
            "F1-Macro: 0.8226\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.88      0.52      0.65        27\n",
            "  NON_BUZZER       0.99      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.99      1291\n",
            "   macro avg       0.93      0.76      0.82      1291\n",
            "weighted avg       0.99      0.99      0.99      1291\n",
            "\n",
            "Saving model to saved_models_tfidf_2_class/RF_TFIDF_Model_TuningFalse_none.pkl ...\n"
          ]
        }
      ],
      "source": [
        "exp_rf_tfidf = run_ml_experiment_tfidf(X_train_tfidf, y_train, X_test_tfidf, y_test, \"rf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "P84vMbMTr_ua",
      "metadata": {
        "id": "P84vMbMTr_ua"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "OwfHTmNfvr4N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwfHTmNfvr4N",
        "outputId": "8fded1b9-c6bb-4611-f702-deb59cab11fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: TFIDF_Model + DT (none)\n",
            "No cache found. Starting training...\n",
            "Fitted Decision Tree with default parameters.\n",
            "Training done in 1.19 seconds.\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9837\n",
            "F1-Macro: 0.7816\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.64      0.52      0.57        27\n",
            "  NON_BUZZER       0.99      0.99      0.99      1264\n",
            "\n",
            "    accuracy                           0.98      1291\n",
            "   macro avg       0.81      0.76      0.78      1291\n",
            "weighted avg       0.98      0.98      0.98      1291\n",
            "\n",
            "Saving model to saved_models_tfidf_2_class/DT_TFIDF_Model_TuningFalse_none.pkl ...\n"
          ]
        }
      ],
      "source": [
        "exp_dt_tfidf = run_ml_experiment_tfidf(X_train_tfidf, y_train, X_test_tfidf, y_test, \"dt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UgTMW3C9sAxq",
      "metadata": {
        "id": "UgTMW3C9sAxq"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "r8FI1B9Hr8ll",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8FI1B9Hr8ll",
        "outputId": "83cbec17-2d76-460d-cafb-48de6fc9268a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: TFIDF_Model + XGB (none)\n",
            "No cache found. Starting training...\n",
            "Fitted XGBoost with default parameters.\n",
            "Training done in 5.18 seconds.\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9806\n",
            "F1-Macro: 0.5641\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.07      0.14        27\n",
            "           1       0.98      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.98      1291\n",
            "   macro avg       0.99      0.54      0.56      1291\n",
            "weighted avg       0.98      0.98      0.97      1291\n",
            "\n",
            "Saving model to saved_models_tfidf_2_class/XGB_TFIDF_Model_TuningFalse_none.pkl ...\n"
          ]
        }
      ],
      "source": [
        "exp_xgb_tfidf = run_ml_experiment_tfidf(X_train_tfidf, y_train_enc, X_test_tfidf, y_test_enc, \"xgb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zDFNkwBMrkHq",
      "metadata": {
        "id": "zDFNkwBMrkHq"
      },
      "source": [
        "## Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FzSqL5uqrlhk",
      "metadata": {
        "id": "FzSqL5uqrlhk"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "mI95FWXtrrqw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI95FWXtrrqw",
        "outputId": "b779b05f-e207-4a90-89e5-bdfec532688e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: TFIDF_Model + SVM (none)\n",
            "No cache found. Starting training...\n",
            "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
            "Best CV F1-Macro: 0.7263\n",
            "Training done in 88.01 seconds.\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9861\n",
            "F1-Macro: 0.8008\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.74      0.52      0.61        27\n",
            "  NON_BUZZER       0.99      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.99      1291\n",
            "   macro avg       0.86      0.76      0.80      1291\n",
            "weighted avg       0.98      0.99      0.98      1291\n",
            "\n",
            "Saving model to saved_models_tfidf_2_class/SVM_TFIDF_Model_TuningTrue_none.pkl ...\n"
          ]
        }
      ],
      "source": [
        "exp_svm_tfidf_ft = run_ml_experiment_tfidf(X_train_tfidf, y_train, X_test_tfidf, y_test, \"svm\", use_tuning=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZeTrbFblrmMo",
      "metadata": {
        "id": "ZeTrbFblrmMo"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "A1S1DYpZruxU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1S1DYpZruxU",
        "outputId": "40bc1b9e-9047-48e1-e694-c76925762d18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: TFIDF_Model + RF (none)\n",
            "No cache found. Starting training...\n",
            "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
            "Best CV F1-Macro: 0.7082\n",
            "Training done in 39.94 seconds.\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9884\n",
            "F1-Macro: 0.8226\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.88      0.52      0.65        27\n",
            "  NON_BUZZER       0.99      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.99      1291\n",
            "   macro avg       0.93      0.76      0.82      1291\n",
            "weighted avg       0.99      0.99      0.99      1291\n",
            "\n",
            "Saving model to saved_models_tfidf_2_class/RF_TFIDF_Model_TuningTrue_none.pkl ...\n"
          ]
        }
      ],
      "source": [
        "exp_rf_tfidf_ft = run_ml_experiment_tfidf(X_train_tfidf, y_train, X_test_tfidf, y_test, \"rf\", use_tuning=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iXV8iXv_rnUd",
      "metadata": {
        "id": "iXV8iXv_rnUd"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "fJnbfWSHrxUI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJnbfWSHrxUI",
        "outputId": "4661e8d8-104c-4b83-aac4-f1783e3b410e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: TFIDF_Model + DT (none)\n",
            "No cache found. Starting training...\n",
            "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
            "Best CV F1-Macro: 0.7361\n",
            "Training done in 11.01 seconds.\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9853\n",
            "F1-Macro: 0.7753\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.75      0.44      0.56        27\n",
            "  NON_BUZZER       0.99      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.99      1291\n",
            "   macro avg       0.87      0.72      0.78      1291\n",
            "weighted avg       0.98      0.99      0.98      1291\n",
            "\n",
            "Saving model to saved_models_tfidf_2_class/DT_TFIDF_Model_TuningTrue_none.pkl ...\n"
          ]
        }
      ],
      "source": [
        "exp_dt_tfidf_ft = run_ml_experiment_tfidf(X_train_tfidf, y_train, X_test_tfidf, y_test, \"dt\", use_tuning=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "loTvhNkUroaU",
      "metadata": {
        "id": "loTvhNkUroaU"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "ZfOGcfIWrzpw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfOGcfIWrzpw",
        "outputId": "d269a7c7-1c0c-4f59-edc8-48411bf75d21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: TFIDF_Model + XGB (none)\n",
            "No cache found. Starting training...\n",
            "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
            "Best CV F1-Macro: 0.5932\n",
            "Training done in 32.62 seconds.\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9837\n",
            "F1-Macro: 0.6959\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.26      0.40        27\n",
            "           1       0.98      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.98      1291\n",
            "   macro avg       0.93      0.63      0.70      1291\n",
            "weighted avg       0.98      0.98      0.98      1291\n",
            "\n",
            "Saving model to saved_models_tfidf_2_class/XGB_TFIDF_Model_TuningTrue_none.pkl ...\n"
          ]
        }
      ],
      "source": [
        "exp_xgb_tfidf_ft = run_ml_experiment_tfidf(X_train_tfidf, y_train_enc, X_test_tfidf, y_test_enc, \"xgb\", use_tuning=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a936vm1gq49y",
      "metadata": {
        "id": "a936vm1gq49y"
      },
      "source": [
        "## Class Weight"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kdBAkdnuq7ox",
      "metadata": {
        "id": "kdBAkdnuq7ox"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "Lyxnr-adrDE4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lyxnr-adrDE4",
        "outputId": "fb979a57-52b1-4967-c76b-294b2cadcfd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: TFIDF_Model + SVM (balanced)\n",
            "No cache found. Starting training...\n",
            "Fitted Support Vector Machine with default parameters.\n",
            "Training done in 8.60 seconds.\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9342\n",
            "F1-Macro: 0.6195\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.18      0.59      0.27        27\n",
            "  NON_BUZZER       0.99      0.94      0.97      1264\n",
            "\n",
            "    accuracy                           0.93      1291\n",
            "   macro avg       0.58      0.77      0.62      1291\n",
            "weighted avg       0.97      0.93      0.95      1291\n",
            "\n",
            "Saving model to saved_models_tfidf_2_class/SVM_TFIDF_Model_TuningFalse_balanced.pkl ...\n"
          ]
        }
      ],
      "source": [
        "exp_svm_tfidf_cw = run_ml_experiment_tfidf(X_train_tfidf, y_train, X_test_tfidf, y_test, \"svm\", use_class_weight=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z17VVXsgq8g0",
      "metadata": {
        "id": "Z17VVXsgq8g0"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "NnKuOOx1rZfC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnKuOOx1rZfC",
        "outputId": "257400b4-fea1-4a82-f01a-5d58c41e70aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: TFIDF_Model + RF (balanced)\n",
            "No cache found. Starting training...\n",
            "Fitted Random Forest with default parameters.\n",
            "Training done in 5.76 seconds.\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9187\n",
            "F1-Macro: 0.5897\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.14      0.56      0.22        27\n",
            "  NON_BUZZER       0.99      0.93      0.96      1264\n",
            "\n",
            "    accuracy                           0.92      1291\n",
            "   macro avg       0.56      0.74      0.59      1291\n",
            "weighted avg       0.97      0.92      0.94      1291\n",
            "\n",
            "Saving model to saved_models_tfidf_2_class/RF_TFIDF_Model_TuningFalse_balanced.pkl ...\n"
          ]
        }
      ],
      "source": [
        "exp_rf_tfidf_cw = run_ml_experiment_tfidf(X_train_tfidf, y_train, X_test_tfidf, y_test, \"rf\", use_class_weight=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "F76NTgaXq9ya",
      "metadata": {
        "id": "F76NTgaXq9ya"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "wj6fLoFhrdVR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj6fLoFhrdVR",
        "outputId": "aa3778a6-5d02-41fb-f941-484e4f283f8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: TFIDF_Model + DT (balanced)\n",
            "No cache found. Starting training...\n",
            "Fitted Decision Tree with default parameters.\n",
            "Training done in 0.91 seconds.\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.8675\n",
            "F1-Macro: 0.5429\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.09      0.59      0.16        27\n",
            "  NON_BUZZER       0.99      0.87      0.93      1264\n",
            "\n",
            "    accuracy                           0.87      1291\n",
            "   macro avg       0.54      0.73      0.54      1291\n",
            "weighted avg       0.97      0.87      0.91      1291\n",
            "\n",
            "Saving model to saved_models_tfidf_2_class/DT_TFIDF_Model_TuningFalse_balanced.pkl ...\n"
          ]
        }
      ],
      "source": [
        "exp_dt_tfidf_cw = run_ml_experiment_tfidf(X_train_tfidf, y_train, X_test_tfidf, y_test, \"dt\", use_class_weight=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6zl3yVxqq-wo",
      "metadata": {
        "id": "6zl3yVxqq-wo"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "hKFWkYicrfgw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKFWkYicrfgw",
        "outputId": "1ac5485a-d43c-4665-f167-c937796f963b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: TFIDF_Model + XGB (balanced)\n",
            "No cache found. Starting training...\n",
            "Fitted XGBoost with default parameters.\n",
            "Training done in 2.53 seconds.\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9806\n",
            "F1-Macro: 0.5641\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.07      0.14        27\n",
            "           1       0.98      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.98      1291\n",
            "   macro avg       0.99      0.54      0.56      1291\n",
            "weighted avg       0.98      0.98      0.97      1291\n",
            "\n",
            "Saving model to saved_models_tfidf_2_class/XGB_TFIDF_Model_TuningFalse_balanced.pkl ...\n"
          ]
        }
      ],
      "source": [
        "exp_xgb_tfidf_cw = run_ml_experiment_tfidf(X_train_tfidf, y_train_enc, X_test_tfidf, y_test_enc, \"xgb\", use_class_weight=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y5MgJ9m4h7OA",
      "metadata": {
        "id": "y5MgJ9m4h7OA"
      },
      "source": [
        "## Fine Tuning - Class Weight"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1QEAnCPZqb5s",
      "metadata": {
        "id": "1QEAnCPZqb5s"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "3ttRbSBPqh6g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ttRbSBPqh6g",
        "outputId": "1d297158-6f43-41d3-9c27-de2aa0bd426e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: TFIDF_Model + SVM (balanced)\n",
            "No cache found. Starting training...\n",
            "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
            "Best CV F1-Macro: 0.6783\n",
            "Training done in 258.63 seconds.\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9613\n",
            "F1-Macro: 0.6924\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.30      0.63      0.40        27\n",
            "  NON_BUZZER       0.99      0.97      0.98      1264\n",
            "\n",
            "    accuracy                           0.96      1291\n",
            "   macro avg       0.65      0.80      0.69      1291\n",
            "weighted avg       0.98      0.96      0.97      1291\n",
            "\n",
            "Saving model to saved_models_tfidf_2_class/SVM_TFIDF_Model_TuningTrue_balanced.pkl ...\n"
          ]
        }
      ],
      "source": [
        "exp_svm_tfidf_cw_ft = run_ml_experiment_tfidf(X_train_tfidf, y_train, X_test_tfidf, y_test, \"svm\", use_class_weight=True, use_tuning=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z0GHMmTSqeyM",
      "metadata": {
        "id": "z0GHMmTSqeyM"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "kFF2FcqTqnc9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFF2FcqTqnc9",
        "outputId": "6fc0414e-ec15-451e-bb57-d5008aa64d98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: TFIDF_Model + RF (balanced)\n",
            "No cache found. Starting training...\n",
            "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
            "Best CV F1-Macro: 0.7034\n",
            "Training done in 37.25 seconds.\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9868\n",
            "F1-Macro: 0.7893\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.86      0.44      0.59        27\n",
            "  NON_BUZZER       0.99      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.99      1291\n",
            "   macro avg       0.92      0.72      0.79      1291\n",
            "weighted avg       0.99      0.99      0.98      1291\n",
            "\n",
            "Saving model to saved_models_tfidf_2_class/RF_TFIDF_Model_TuningTrue_balanced.pkl ...\n"
          ]
        }
      ],
      "source": [
        "exp_rf_tfidf_cw_ft = run_ml_experiment_tfidf(X_train_tfidf, y_train, X_test_tfidf, y_test, \"rf\", use_class_weight=True, use_tuning=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PVA2JjUGqf6q",
      "metadata": {
        "id": "PVA2JjUGqf6q"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "QLEE5IB7qqQz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLEE5IB7qqQz",
        "outputId": "d2adfc39-dbf6-4429-8e13-027c4eb63e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: TFIDF_Model + DT (balanced)\n",
            "No cache found. Starting training...\n",
            "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
            "Best CV F1-Macro: 0.6585\n",
            "Training done in 10.22 seconds.\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9620\n",
            "F1-Macro: 0.6546\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.26      0.44      0.33        27\n",
            "  NON_BUZZER       0.99      0.97      0.98      1264\n",
            "\n",
            "    accuracy                           0.96      1291\n",
            "   macro avg       0.62      0.71      0.65      1291\n",
            "weighted avg       0.97      0.96      0.97      1291\n",
            "\n",
            "Saving model to saved_models_tfidf_2_class/DT_TFIDF_Model_TuningTrue_balanced.pkl ...\n"
          ]
        }
      ],
      "source": [
        "exp_dt_tfidf_cw_ft = run_ml_experiment_tfidf(X_train_tfidf, y_train, X_test_tfidf, y_test, \"dt\", use_class_weight=True, use_tuning=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ob1Xlnakh8_J",
      "metadata": {
        "id": "ob1Xlnakh8_J"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "2vfiruIFh_Ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vfiruIFh_Ce",
        "outputId": "78fb8714-0013-4821-e892-947ed0e4708f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: TFIDF_Model + XGB (balanced)\n",
            "No cache found. Starting training...\n",
            "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
            "Best CV F1-Macro: 0.5932\n",
            "Training done in 32.12 seconds.\n",
            "\n",
            "Evaluation on TEST SET\n",
            "Accuracy: 0.9837\n",
            "F1-Macro: 0.6959\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.26      0.40        27\n",
            "           1       0.98      1.00      0.99      1264\n",
            "\n",
            "    accuracy                           0.98      1291\n",
            "   macro avg       0.93      0.63      0.70      1291\n",
            "weighted avg       0.98      0.98      0.98      1291\n",
            "\n",
            "Saving model to saved_models_tfidf_2_class/XGB_TFIDF_Model_TuningTrue_balanced.pkl ...\n"
          ]
        }
      ],
      "source": [
        "exp_xgb_tfidf_cw_ft = run_ml_experiment_tfidf(X_train_tfidf, y_train_enc, X_test_tfidf, y_test_enc, \"xgb\", use_class_weight=True, use_tuning=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RWmENuBfw4_E",
      "metadata": {
        "id": "RWmENuBfw4_E"
      },
      "source": [
        "## Table Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "oh4Ydl9Tw65j",
      "metadata": {
        "id": "oh4Ydl9Tw65j"
      },
      "outputs": [],
      "source": [
        "all_experiments_tfidf = [exp_svm_tfidf, exp_svm_tfidf_cw, exp_svm_tfidf_cw_ft, exp_svm_tfidf_ft,\n",
        "                   exp_rf_tfidf, exp_rf_tfidf_cw, exp_rf_tfidf_cw_ft, exp_rf_tfidf_ft,\n",
        "                   exp_dt_tfidf, exp_dt_tfidf_cw, exp_dt_tfidf_cw_ft, exp_dt_tfidf_ft,\n",
        "                   exp_xgb_tfidf, exp_xgb_tfidf_cw, exp_xgb_tfidf_cw_ft, exp_xgb_tfidf_ft]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "tvYm5p7qzRYX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "tvYm5p7qzRYX",
        "outputId": "981e88d4-cf2f-40cd-94ce-83b06a56084a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== FINAL COMPARISON TABLE - TF-IDF ===\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_result\",\n  \"rows\": 16,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Support Vector Machine\",\n          \"XGBoost\",\n          \"Random Forest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Balance Strategy\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Class Weight\",\n          \"None\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tuning\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision (Buzzer)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3284167779858538,\n        \"min\": 0.09090909090909091,\n        \"max\": 1.0,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          1.0,\n          0.1388888888888889\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall (Buzzer)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17370265076413607,\n        \"min\": 0.07407407407407407,\n        \"max\": 0.6296296296296297,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.4444444444444444,\n          0.5925925925925926\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score (Buzzer)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18729978515578838,\n        \"min\": 0.13793103448275862,\n        \"max\": 0.6511627906976745,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.13793103448275862,\n          0.27350427350427353\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score (Macro)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09935781085574041,\n        \"min\": 0.5428782636244479,\n        \"max\": 0.822627476483142,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.5640693166930049,\n          0.619510757441792\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_result"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f045f243-af12-4b6a-9458-53bebe8ca04e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Balance Strategy</th>\n",
              "      <th>Tuning</th>\n",
              "      <th>Precision (Buzzer)</th>\n",
              "      <th>Recall (Buzzer)</th>\n",
              "      <th>F1 Score (Buzzer)</th>\n",
              "      <th>F1 Score (Macro)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.519</td>\n",
              "      <td>0.651</td>\n",
              "      <td>0.823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.519</td>\n",
              "      <td>0.651</td>\n",
              "      <td>0.823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Support Vector Machine</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>0.737</td>\n",
              "      <td>0.519</td>\n",
              "      <td>0.609</td>\n",
              "      <td>0.801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>Class Weight</td>\n",
              "      <td>True</td>\n",
              "      <td>0.857</td>\n",
              "      <td>0.444</td>\n",
              "      <td>0.585</td>\n",
              "      <td>0.789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>0.636</td>\n",
              "      <td>0.519</td>\n",
              "      <td>0.571</td>\n",
              "      <td>0.782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.444</td>\n",
              "      <td>0.558</td>\n",
              "      <td>0.775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Support Vector Machine</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>0.846</td>\n",
              "      <td>0.407</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>Class Weight</td>\n",
              "      <td>True</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.259</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.259</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Support Vector Machine</td>\n",
              "      <td>Class Weight</td>\n",
              "      <td>True</td>\n",
              "      <td>0.298</td>\n",
              "      <td>0.630</td>\n",
              "      <td>0.405</td>\n",
              "      <td>0.692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>Class Weight</td>\n",
              "      <td>True</td>\n",
              "      <td>0.261</td>\n",
              "      <td>0.444</td>\n",
              "      <td>0.329</td>\n",
              "      <td>0.655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Support Vector Machine</td>\n",
              "      <td>Class Weight</td>\n",
              "      <td>False</td>\n",
              "      <td>0.178</td>\n",
              "      <td>0.593</td>\n",
              "      <td>0.274</td>\n",
              "      <td>0.620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>Class Weight</td>\n",
              "      <td>False</td>\n",
              "      <td>0.139</td>\n",
              "      <td>0.556</td>\n",
              "      <td>0.222</td>\n",
              "      <td>0.590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>Class Weight</td>\n",
              "      <td>False</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.074</td>\n",
              "      <td>0.138</td>\n",
              "      <td>0.564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.074</td>\n",
              "      <td>0.138</td>\n",
              "      <td>0.564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>Class Weight</td>\n",
              "      <td>False</td>\n",
              "      <td>0.091</td>\n",
              "      <td>0.593</td>\n",
              "      <td>0.158</td>\n",
              "      <td>0.543</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f045f243-af12-4b6a-9458-53bebe8ca04e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f045f243-af12-4b6a-9458-53bebe8ca04e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f045f243-af12-4b6a-9458-53bebe8ca04e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-28614c51-97d9-4922-9f93-1925d149207c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-28614c51-97d9-4922-9f93-1925d149207c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-28614c51-97d9-4922-9f93-1925d149207c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_30bd53eb-9475-457b-9f4c-313983eddffa\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_result')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_30bd53eb-9475-457b-9f4c-313983eddffa button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_result');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                     Model Balance Strategy  Tuning  Precision (Buzzer)  \\\n",
              "0            Random Forest             None    True               0.875   \n",
              "1            Random Forest             None   False               0.875   \n",
              "2   Support Vector Machine             None    True               0.737   \n",
              "3            Random Forest     Class Weight    True               0.857   \n",
              "4            Decision Tree             None   False               0.636   \n",
              "5            Decision Tree             None    True               0.750   \n",
              "6   Support Vector Machine             None   False               0.846   \n",
              "7                  XGBoost     Class Weight    True               0.875   \n",
              "8                  XGBoost             None    True               0.875   \n",
              "9   Support Vector Machine     Class Weight    True               0.298   \n",
              "10           Decision Tree     Class Weight    True               0.261   \n",
              "11  Support Vector Machine     Class Weight   False               0.178   \n",
              "12           Random Forest     Class Weight   False               0.139   \n",
              "13                 XGBoost     Class Weight   False               1.000   \n",
              "14                 XGBoost             None   False               1.000   \n",
              "15           Decision Tree     Class Weight   False               0.091   \n",
              "\n",
              "    Recall (Buzzer)  F1 Score (Buzzer)  F1 Score (Macro)  \n",
              "0             0.519              0.651             0.823  \n",
              "1             0.519              0.651             0.823  \n",
              "2             0.519              0.609             0.801  \n",
              "3             0.444              0.585             0.789  \n",
              "4             0.519              0.571             0.782  \n",
              "5             0.444              0.558             0.775  \n",
              "6             0.407              0.550             0.771  \n",
              "7             0.259              0.400             0.696  \n",
              "8             0.259              0.400             0.696  \n",
              "9             0.630              0.405             0.692  \n",
              "10            0.444              0.329             0.655  \n",
              "11            0.593              0.274             0.620  \n",
              "12            0.556              0.222             0.590  \n",
              "13            0.074              0.138             0.564  \n",
              "14            0.074              0.138             0.564  \n",
              "15            0.593              0.158             0.543  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_result = create_comparison_table(all_experiments_tfidf)\n",
        "\n",
        "print(\"\\n=== FINAL COMPARISON TABLE - TF-IDF ===\")\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "df_result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f133bc45",
      "metadata": {
        "id": "f133bc45"
      },
      "source": [
        "The results show that Random Forest without imbalance handling, both with and without tuning, achieves the strongest performance with an F1-Macro score of 0.823 and 0.651 F1-Score (Buzzer), making it the best-performing model under the TF-IDF representation. This indicates that Random Forest is highly effective at capturing patterns from the sparse, high-dimensional TF-IDF features.\n",
        "\n",
        "Random Forest with tuning achieves the highest performance (F1-Macro 0.823) on TF-IDF features because tree-based models handle sparse, high-dimensional data effectively. Hyperparameter tuning further improves the model's ability to capture class patterns, outperforming SVM, XGBoost, and Decision Tree models.\n",
        "\n",
        "Support Vector Machine (SVM) also performs well, but its F1-Macro scores remain slightly lower than Random Forest, suggesting that the TF-IDF feature space may be less linearly separable compared to FastText, reducing SVM’s advantage.\n",
        "\n",
        "XGBoost and Decision Tree models generally show weaker macro-F1, with Decision Tree being the least stable model, likely due to overfitting on sparse TF-IDF vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z0QjqtRfEcf2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "z0QjqtRfEcf2",
        "outputId": "23d426d6-2923-4a06-c0f1-8d2acb7412fb"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_6fa7e112-2a96-4097-8d64-82d22ea58f63\", \"saved_models_tfidf_2_class.zip\", 11123281)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive('saved_models_tfidf_2_class', 'zip', 'saved_models_tfidf_2_class')\n",
        "\n",
        "files.download('saved_models_tfidf_2_class.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8adbc055",
      "metadata": {
        "id": "8adbc055"
      },
      "source": [
        "# IndoBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44615096",
      "metadata": {
        "id": "44615096",
        "outputId": "4dcbeab6-c727-4a72-bde5-73a6ac71f8c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved in ./models/indobert\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "model_name = \"indolem/indobertweet-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"./models/indobert\")\n",
        "model = AutoModel.from_pretrained(model_name, cache_dir=\"./models/indobert\")\n",
        "\n",
        "print(\"Model saved in ./models/indobert\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29a55dfc",
      "metadata": {
        "id": "29a55dfc"
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c4bf576",
      "metadata": {
        "id": "0c4bf576"
      },
      "outputs": [],
      "source": [
        "val_size = 15/85\n",
        "\n",
        "X_train_indobert, X_val_indobert, y_train_indobert, y_val_indobert = train_test_split(\n",
        "    X_train, y_train, test_size=val_size, random_state=42, stratify=y_train\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f40e75d6",
      "metadata": {
        "id": "f40e75d6",
        "outputId": "e6f0f3e6-89f3-44f0-c2e6-d3a07c3a6e52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overlap train-val: 0\n",
            "Overlap train-test: 0\n",
            "Overlap val-test: 0\n"
          ]
        }
      ],
      "source": [
        "train_texts = set(X_train_indobert)\n",
        "val_texts = set(X_val_indobert)\n",
        "test_texts = set(X_test)\n",
        "\n",
        "print(f\"Overlap train-val: {len(train_texts.intersection(val_texts))}\")\n",
        "print(f\"Overlap train-test: {len(train_texts.intersection(test_texts))}\")\n",
        "print(f\"Overlap val-test: {len(val_texts.intersection(test_texts))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43a2a0df",
      "metadata": {
        "id": "43a2a0df"
      },
      "source": [
        "## Make Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd60f022",
      "metadata": {
        "id": "bd60f022",
        "outputId": "39efdaa8-bc95-49d7-a075-f75cf8a23e57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 6021\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1291\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1291\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "dataset = DatasetDict({\n",
        "    \"train\": Dataset.from_dict({\"text\": X_train_indobert, \"label\": y_train_indobert}),\n",
        "    \"validation\": Dataset.from_dict({\"text\": X_val_indobert, \"label\": y_val_indobert}),\n",
        "    \"test\": Dataset.from_dict({\"text\": X_test, \"label\": y_test}),\n",
        "})\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50dfe717",
      "metadata": {
        "id": "50dfe717"
      },
      "source": [
        "## Y Encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8e91e54",
      "metadata": {
        "id": "c8e91e54",
        "outputId": "1f22bf7a-12eb-459a-e392-70b5761bc307"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 6021/6021 [00:00<00:00, 12150.48 examples/s]\n",
            "Map: 100%|██████████| 1291/1291 [00:00<00:00, 9851.32 examples/s] \n",
            "Map: 100%|██████████| 1291/1291 [00:00<00:00, 11541.80 examples/s]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "train_labels = dataset[\"train\"][\"label\"]\n",
        "le = LabelEncoder()\n",
        "le.fit(train_labels)\n",
        "\n",
        "def encode_labels(batch):\n",
        "    batch[\"label\"] = [le.transform([l])[0] if l in le.classes_ else -1 for l in batch[\"label\"]]\n",
        "    return batch\n",
        "\n",
        "dataset = dataset.map(encode_labels, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63459f5e",
      "metadata": {
        "id": "63459f5e"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b8a4d9e",
      "metadata": {
        "id": "6b8a4d9e",
        "outputId": "8037c72c-1d42-4a8c-c962-46a3571b8349"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map:   0%|          | 0/6021 [00:00<?, ? examples/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 6021/6021 [00:00<00:00, 12463.40 examples/s]\n",
            "Map: 100%|██████████| 1291/1291 [00:00<00:00, 14342.75 examples/s]\n",
            "Map: 100%|██████████| 1291/1291 [00:00<00:00, 15805.66 examples/s]\n"
          ]
        }
      ],
      "source": [
        "def preprocess_indobert(data):\n",
        "    return tokenizer(data[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "dataset = dataset.map(preprocess_indobert, batched=True)\n",
        "dataset = dataset.remove_columns([\"text\"])\n",
        "dataset.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"label\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b28c5db",
      "metadata": {
        "id": "0b28c5db"
      },
      "source": [
        "## Class Weight IndoBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ab5df4a",
      "metadata": {
        "id": "4ab5df4a",
        "outputId": "c254600f-3759-4cdb-e1f6-e85a4cf8c634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Weights: tensor([25.7308,  0.5099], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "labels_array = np.array(y_train_indobert)\n",
        "\n",
        "classes = np.unique(labels_array)\n",
        "class_weights = compute_class_weight(\"balanced\", classes=classes, y=labels_array)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).cuda()\n",
        "print(\"Class Weights:\", class_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bab378e9",
      "metadata": {
        "id": "bab378e9"
      },
      "source": [
        "## Custom IndoBERT Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fe0abf1",
      "metadata": {
        "id": "9fe0abf1",
        "outputId": "88e3fda6-0493-4cdf-b6bf-b07931f2311a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobertweet-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(classes),\n",
        "    cache_dir=\"./models/indobert\"\n",
        ")\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
        "\n",
        "        pt = torch.exp(-ce_loss)\n",
        "\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "class FocalLossTrainer(Trainer):\n",
        "    def __init__(self, alpha=None, gamma=2.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.focal_loss = FocalLoss(alpha=alpha, gamma=gamma)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.get(\"labels\") if \"labels\" in inputs else inputs.get(\"label\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        loss = self.focal_loss(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffedefd7",
      "metadata": {
        "id": "ffedefd7"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d1f017",
      "metadata": {
        "id": "20d1f017",
        "outputId": "39a74c77-e245-41a1-f409-89692cda7794"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1885' max='1885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1885/1885 07:23, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.031100</td>\n",
              "      <td>0.021305</td>\n",
              "      <td>0.984508</td>\n",
              "      <td>0.732911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.012900</td>\n",
              "      <td>0.018593</td>\n",
              "      <td>0.986832</td>\n",
              "      <td>0.798978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.005100</td>\n",
              "      <td>0.023471</td>\n",
              "      <td>0.985283</td>\n",
              "      <td>0.752675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>0.021592</td>\n",
              "      <td>0.986832</td>\n",
              "      <td>0.798978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>0.024392</td>\n",
              "      <td>0.986832</td>\n",
              "      <td>0.789338</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1885, training_loss=0.010520842414477776, metrics={'train_runtime': 445.1956, 'train_samples_per_second': 67.622, 'train_steps_per_second': 4.234, 'total_flos': 1980239580403200.0, 'train_loss': 0.010520842414477776, 'epoch': 5.0})"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"f1_macro\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
        "    }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results/indobert\",\n",
        "    save_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    fp16=True,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_macro\",\n",
        "    greater_is_better=True,\n",
        "    logging_steps=50\n",
        ")\n",
        "\n",
        "trainer = FocalLossTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cd91175",
      "metadata": {
        "id": "4cd91175"
      },
      "source": [
        "The model shows consistent performance improvement over the 5 training epochs. Training loss decreases steadily from 0.0276 to 0.0016, indicating that the model is learning effectively. Validation loss remains stable across epochs, with only minor fluctuations, showing no signs of overfitting.\n",
        "\n",
        "Accuracy increases slightly from 0.9837 to 0.9876, while the F1-Macro score improves more substantially from 0.6959 to 0.7968, suggesting that IndoBERT becomes better at correctly handling both majority and minority classes as training progresses. The stable gap between training and validation metrics indicates a well-regularized model with good generalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91e42b68",
      "metadata": {
        "id": "91e42b68",
        "outputId": "f7e698fe-3ae8-46ed-b448-a55b9dfa683d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report IndoBERT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BUZZER       0.54      0.52      0.53        27\n",
            "  NON_BUZZER       0.99      0.99      0.99      1264\n",
            "\n",
            "    accuracy                           0.98      1291\n",
            "   macro avg       0.76      0.75      0.76      1291\n",
            "weighted avg       0.98      0.98      0.98      1291\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_results = trainer.predict(dataset[\"test\"])\n",
        "\n",
        "preds = np.argmax(test_results.predictions, axis=-1)\n",
        "\n",
        "labels = test_results.label_ids\n",
        "\n",
        "print(\"Classification Report IndoBERT\")\n",
        "print(classification_report(labels, preds, target_names=le.classes_.astype(str), digits=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "890c948d",
      "metadata": {},
      "source": [
        "IndoBERT failed to beat our machine learning models in predicting the minority class. It struggle to detect the \"Buzzer\", showing only 0.53 F1-Score in \"Buzzer\" class."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fb1d90f",
      "metadata": {
        "id": "8fb1d90f"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54b53b10",
      "metadata": {
        "id": "54b53b10"
      },
      "source": [
        "Based on the evaluation using Precision, Recall, and F1-Score, the TF-IDF representation delivers the strongest overall performance across all tested models. Random Forest paired with TF-IDF consistently achieves the highest macro scores, showing superior ability to distinguish between buzzer and non-buzzer comments even under class imbalance. FastText performs reasonably well but remains below TF-IDF, as its subword semantic features do not match the lexical clarity offered by TF-IDF for this task. Meanwhile, IndoBERT achieves very high accuracy, but its F1-Macro remains slightly lower than TF-IDF, indicating that the model still struggles to fully capture the minority class despite its contextual understanding. Overall, TF-IDF provides the most effective and balanced classification performance for buzzer detection in this study."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ec78671",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "text_mining",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
